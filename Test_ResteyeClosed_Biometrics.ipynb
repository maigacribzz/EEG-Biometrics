{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from random import choice\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import  PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1962 entries, 0 to 1961\n",
      "Columns: 562 entries, 0 to 561\n",
      "dtypes: float64(560), int64(2)\n",
      "memory usage: 8.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('Train_RestClosed_Biometrics.xlsx',header=None)\n",
    "df.head(5)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(561,1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.999226</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.000598</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>...</td>\n",
       "      <td>17.915858</td>\n",
       "      <td>14.042900</td>\n",
       "      <td>22.009515</td>\n",
       "      <td>28.770245</td>\n",
       "      <td>9.993780</td>\n",
       "      <td>6.576365</td>\n",
       "      <td>15.720314</td>\n",
       "      <td>7.852062</td>\n",
       "      <td>8.861143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.999227</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>...</td>\n",
       "      <td>-145.064462</td>\n",
       "      <td>-16.658530</td>\n",
       "      <td>-24.035528</td>\n",
       "      <td>57.730532</td>\n",
       "      <td>191.936356</td>\n",
       "      <td>7.793836</td>\n",
       "      <td>33.896247</td>\n",
       "      <td>3.553457</td>\n",
       "      <td>20.672913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.999215</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000777</td>\n",
       "      <td>-0.000783</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.585202</td>\n",
       "      <td>-14.675864</td>\n",
       "      <td>-31.486464</td>\n",
       "      <td>-60.325533</td>\n",
       "      <td>-272.218604</td>\n",
       "      <td>9.209448</td>\n",
       "      <td>42.144403</td>\n",
       "      <td>4.082240</td>\n",
       "      <td>20.512868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.999227</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.412917</td>\n",
       "      <td>-7.818255</td>\n",
       "      <td>-11.713346</td>\n",
       "      <td>-8.955803</td>\n",
       "      <td>-9.297744</td>\n",
       "      <td>-10.400048</td>\n",
       "      <td>-9.255250</td>\n",
       "      <td>-11.016431</td>\n",
       "      <td>-15.208149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.999217</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.393234</td>\n",
       "      <td>-6.826698</td>\n",
       "      <td>-8.593136</td>\n",
       "      <td>-9.570859</td>\n",
       "      <td>-7.218773</td>\n",
       "      <td>-7.283716</td>\n",
       "      <td>-7.051959</td>\n",
       "      <td>-6.953481</td>\n",
       "      <td>-12.507100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.999226  0.002347  0.000383  0.000016  0.000416 -0.000108 -0.000598   \n",
       "1 -0.999227  0.000758  0.000864  0.000637  0.000409  0.000352  0.000542   \n",
       "2 -0.999215  0.001454  0.000775 -0.000121 -0.000777 -0.000783 -0.000203   \n",
       "3 -0.999227  0.001050  0.000486 -0.000134 -0.000456 -0.000346  0.000140   \n",
       "4 -0.999217 -0.000594 -0.000429  0.000166  0.000845  0.001161  0.001033   \n",
       "\n",
       "        7         8         9    ...         551        552        553  \\\n",
       "0  0.000050  0.001248  0.001038  ...   17.915858  14.042900  22.009515   \n",
       "1  0.000676  0.000440 -0.000119  ... -145.064462 -16.658530 -24.035528   \n",
       "2  0.000500  0.000822  0.000616  ...  -19.585202 -14.675864 -31.486464   \n",
       "3  0.000782  0.001285  0.001282  ...   -7.412917  -7.818255 -11.713346   \n",
       "4  0.000494 -0.000084 -0.000448  ...   -6.393234  -6.826698  -8.593136   \n",
       "\n",
       "         554         555        556        557        558        559  560  \n",
       "0  28.770245    9.993780   6.576365  15.720314   7.852062   8.861143    1  \n",
       "1  57.730532  191.936356   7.793836  33.896247   3.553457  20.672913    1  \n",
       "2 -60.325533 -272.218604   9.209448  42.144403   4.082240  20.512868    1  \n",
       "3  -8.955803   -9.297744 -10.400048  -9.255250 -11.016431 -15.208149    1  \n",
       "4  -9.570859   -7.218773  -7.283716  -7.051959  -6.953481 -12.507100    1  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.965875</td>\n",
       "      <td>0.633873</td>\n",
       "      <td>-0.534381</td>\n",
       "      <td>0.199050</td>\n",
       "      <td>0.160097</td>\n",
       "      <td>-0.054167</td>\n",
       "      <td>-0.073747</td>\n",
       "      <td>-0.005692</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>-0.027626</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.949788</td>\n",
       "      <td>-1.427521</td>\n",
       "      <td>28.513481</td>\n",
       "      <td>-1.287785</td>\n",
       "      <td>-1.189334</td>\n",
       "      <td>-1.608207</td>\n",
       "      <td>-0.347157</td>\n",
       "      <td>-0.882891</td>\n",
       "      <td>0.537365</td>\n",
       "      <td>10.978084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.063824</td>\n",
       "      <td>0.324207</td>\n",
       "      <td>0.307469</td>\n",
       "      <td>0.284217</td>\n",
       "      <td>0.191353</td>\n",
       "      <td>0.168694</td>\n",
       "      <td>0.113198</td>\n",
       "      <td>0.100740</td>\n",
       "      <td>0.075869</td>\n",
       "      <td>0.069632</td>\n",
       "      <td>...</td>\n",
       "      <td>6.704258</td>\n",
       "      <td>10.413219</td>\n",
       "      <td>1112.119934</td>\n",
       "      <td>7.701526</td>\n",
       "      <td>18.211491</td>\n",
       "      <td>20.720284</td>\n",
       "      <td>22.810270</td>\n",
       "      <td>13.347676</td>\n",
       "      <td>68.006297</td>\n",
       "      <td>6.027138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.999418</td>\n",
       "      <td>-0.320190</td>\n",
       "      <td>-0.936939</td>\n",
       "      <td>-0.397983</td>\n",
       "      <td>-0.767641</td>\n",
       "      <td>-0.617287</td>\n",
       "      <td>-0.360364</td>\n",
       "      <td>-0.254651</td>\n",
       "      <td>-0.462296</td>\n",
       "      <td>-0.365841</td>\n",
       "      <td>...</td>\n",
       "      <td>-145.064462</td>\n",
       "      <td>-389.563193</td>\n",
       "      <td>-694.131562</td>\n",
       "      <td>-86.624231</td>\n",
       "      <td>-327.534398</td>\n",
       "      <td>-664.297879</td>\n",
       "      <td>-295.835914</td>\n",
       "      <td>-95.958366</td>\n",
       "      <td>-165.379147</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.989275</td>\n",
       "      <td>0.654850</td>\n",
       "      <td>-0.770208</td>\n",
       "      <td>-0.002498</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>-0.191279</td>\n",
       "      <td>-0.159513</td>\n",
       "      <td>-0.080195</td>\n",
       "      <td>-0.027073</td>\n",
       "      <td>-0.065742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.936750</td>\n",
       "      <td>-0.931313</td>\n",
       "      <td>-0.935075</td>\n",
       "      <td>-0.936555</td>\n",
       "      <td>-0.957408</td>\n",
       "      <td>-0.934876</td>\n",
       "      <td>-0.940461</td>\n",
       "      <td>-0.938372</td>\n",
       "      <td>-0.952986</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.970021</td>\n",
       "      <td>0.778190</td>\n",
       "      <td>-0.659457</td>\n",
       "      <td>0.113443</td>\n",
       "      <td>0.210158</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.080074</td>\n",
       "      <td>-0.001960</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.917263</td>\n",
       "      <td>-0.911020</td>\n",
       "      <td>-0.917064</td>\n",
       "      <td>-0.916796</td>\n",
       "      <td>-0.947850</td>\n",
       "      <td>-0.911298</td>\n",
       "      <td>-0.927029</td>\n",
       "      <td>-0.919982</td>\n",
       "      <td>-0.937314</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.959206</td>\n",
       "      <td>0.835873</td>\n",
       "      <td>-0.354083</td>\n",
       "      <td>0.429690</td>\n",
       "      <td>0.309837</td>\n",
       "      <td>0.064991</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.053839</td>\n",
       "      <td>0.051402</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.889748</td>\n",
       "      <td>-0.862366</td>\n",
       "      <td>-0.887571</td>\n",
       "      <td>-0.888744</td>\n",
       "      <td>-0.928823</td>\n",
       "      <td>-0.845945</td>\n",
       "      <td>-0.901632</td>\n",
       "      <td>-0.873112</td>\n",
       "      <td>-0.918500</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-0.002383</td>\n",
       "      <td>0.934300</td>\n",
       "      <td>0.149601</td>\n",
       "      <td>0.894877</td>\n",
       "      <td>0.487911</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>0.451442</td>\n",
       "      <td>0.453086</td>\n",
       "      <td>0.327179</td>\n",
       "      <td>0.201303</td>\n",
       "      <td>...</td>\n",
       "      <td>61.156411</td>\n",
       "      <td>111.516182</td>\n",
       "      <td>48830.739875</td>\n",
       "      <td>205.092349</td>\n",
       "      <td>448.332786</td>\n",
       "      <td>144.915192</td>\n",
       "      <td>612.492324</td>\n",
       "      <td>502.782246</td>\n",
       "      <td>2952.137009</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  1962.000000  1962.000000  1962.000000  1962.000000  1962.000000   \n",
       "mean     -0.965875     0.633873    -0.534381     0.199050     0.160097   \n",
       "std       0.063824     0.324207     0.307469     0.284217     0.191353   \n",
       "min      -0.999418    -0.320190    -0.936939    -0.397983    -0.767641   \n",
       "25%      -0.989275     0.654850    -0.770208    -0.002498     0.000817   \n",
       "50%      -0.970021     0.778190    -0.659457     0.113443     0.210158   \n",
       "75%      -0.959206     0.835873    -0.354083     0.429690     0.309837   \n",
       "max      -0.002383     0.934300     0.149601     0.894877     0.487911   \n",
       "\n",
       "                 5            6            7            8            9  ...  \\\n",
       "count  1962.000000  1962.000000  1962.000000  1962.000000  1962.000000  ...   \n",
       "mean     -0.054167    -0.073747    -0.005692     0.005750    -0.027626  ...   \n",
       "std       0.168694     0.113198     0.100740     0.075869     0.069632  ...   \n",
       "min      -0.617287    -0.360364    -0.254651    -0.462296    -0.365841  ...   \n",
       "25%      -0.191279    -0.159513    -0.080195    -0.027073    -0.065742  ...   \n",
       "50%      -0.000230    -0.080074    -0.001960     0.001285    -0.001665  ...   \n",
       "75%       0.064991     0.000658     0.053839     0.051402     0.012955  ...   \n",
       "max       0.266482     0.451442     0.453086     0.327179     0.201303  ...   \n",
       "\n",
       "               551          552           553          554          555  \\\n",
       "count  1962.000000  1962.000000   1962.000000  1962.000000  1962.000000   \n",
       "mean     -1.949788    -1.427521     28.513481    -1.287785    -1.189334   \n",
       "std       6.704258    10.413219   1112.119934     7.701526    18.211491   \n",
       "min    -145.064462  -389.563193   -694.131562   -86.624231  -327.534398   \n",
       "25%      -0.936750    -0.931313     -0.935075    -0.936555    -0.957408   \n",
       "50%      -0.917263    -0.911020     -0.917064    -0.916796    -0.947850   \n",
       "75%      -0.889748    -0.862366     -0.887571    -0.888744    -0.928823   \n",
       "max      61.156411   111.516182  48830.739875   205.092349   448.332786   \n",
       "\n",
       "               556          557          558          559       Target  \n",
       "count  1962.000000  1962.000000  1962.000000  1962.000000  1962.000000  \n",
       "mean     -1.608207    -0.347157    -0.882891     0.537365    10.978084  \n",
       "std      20.720284    22.810270    13.347676    68.006297     6.027138  \n",
       "min    -664.297879  -295.835914   -95.958366  -165.379147     1.000000  \n",
       "25%      -0.934876    -0.940461    -0.938372    -0.952986     6.000000  \n",
       "50%      -0.911298    -0.927029    -0.919982    -0.937314    11.000000  \n",
       "75%      -0.845945    -0.901632    -0.873112    -0.918500    16.000000  \n",
       "max     144.915192   612.492324   502.782246  2952.137009    21.000000  \n",
       "\n",
       "[8 rows x 561 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns = {560:'Target'}, inplace=True)\n",
    "print(df['Target'].unique())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6552"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().any()\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score = df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(mean_score, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1962 entries, 0 to 1961\n",
      "Columns: 561 entries, 0 to Target\n",
      "dtypes: float64(560), int64(1)\n",
      "memory usage: 8.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_auth_dataset(df, subj, ratio=3):\n",
    "        subj_df = df.copy()\n",
    "        subj_df.loc[(subj_df['Target'] != subj), 'Target'] = 0\n",
    "        subj_df.loc[(subj_df['Target'] == subj), 'Target'] = 1\n",
    "        gen_df = subj_df[subj_df['Target'] == 1]\n",
    "        no_gen = gen_df.shape[0]\n",
    "        imp_df = subj_df[subj_df['Target'] == 0].sample(n = no_gen * ratio)\n",
    "        auth_df = pd.concat([gen_df, imp_df])\n",
    "        return auth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = generate_auth_dataset(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    279\n",
       "1     93\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df1.iloc[:, :-1].values, df1.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data = scaler.transform(X_Feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(372, 30)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data)\n",
    "x_pca = pca.transform(scaled_data)\n",
    "x_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_excel('Test_RestClosed_Biometrics.xlsx',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 971 entries, 0 to 970\n",
      "Columns: 561 entries, 0 to 560\n",
      "dtypes: float64(560), int64(1)\n",
      "memory usage: 4.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3360"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.rename(columns = {560:'Target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_test = generate_auth_dataset(df_test, 1, ratio=3)\n",
    "df1_test['Target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    138\n",
       "1     46\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_test['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df1_test.iloc[:, :-1].values, df1_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test = scaler.transform(X_Feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 30)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data_test)\n",
    "x_pca_test = pca.transform(scaled_data_test)\n",
    "x_pca_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_pca_test\n",
    "X_train = x_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[129   9]\n",
      " [ 46   0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.82       138\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.70       184\n",
      "   macro avg       0.37      0.47      0.41       184\n",
      "weighted avg       0.55      0.70      0.62       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test1 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110  13]\n",
      " [  0  41]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94       123\n",
      "           1       0.76      1.00      0.86        41\n",
      "\n",
      "    accuracy                           0.92       164\n",
      "   macro avg       0.88      0.95      0.90       164\n",
      "weighted avg       0.94      0.92      0.92       164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = generate_auth_dataset(df,2, ratio=3)\n",
    "df2_test = generate_auth_dataset(df_test,2, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df2.iloc[:, :-1].values, df2.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data2 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df2_test.iloc[:, :-1].values, df2_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test2 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data2)\n",
    "x_pca2 = pca.transform(scaled_data2)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data_test2)\n",
    "x_pca_test2 = pca.transform(scaled_data_test2)\n",
    "\n",
    "X_test = x_pca_test2\n",
    "X_train = x_pca2\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test2 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[119   4]\n",
      " [ 41   0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84       123\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.73       164\n",
      "   macro avg       0.37      0.48      0.42       164\n",
      "weighted avg       0.56      0.73      0.63       164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = generate_auth_dataset(df,3, ratio=3)\n",
    "df3_test = generate_auth_dataset(df_test,3, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df3.iloc[:, :-1].values, df3.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data3 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df3_test.iloc[:, :-1].values, df3_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test3 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data3)\n",
    "x_pca3 = pca.transform(scaled_data3)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data_test3)\n",
    "x_pca_test3 = pca.transform(scaled_data_test3)\n",
    "\n",
    "X_test = x_pca_test3\n",
    "X_train = x_pca3\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test3 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[132   6]\n",
      " [ 37   9]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86       138\n",
      "           1       0.60      0.20      0.30        46\n",
      "\n",
      "    accuracy                           0.77       184\n",
      "   macro avg       0.69      0.58      0.58       184\n",
      "weighted avg       0.74      0.77      0.72       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = generate_auth_dataset(df,4, ratio=3)\n",
    "df4_test = generate_auth_dataset(df_test,4, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df4.iloc[:, :-1].values, df4.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data4 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df4_test.iloc[:, :-1].values, df4_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test4 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data4)\n",
    "x_pca4 = pca.transform(scaled_data4)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data_test4)\n",
    "x_pca_test4 = pca.transform(scaled_data_test4)\n",
    "\n",
    "X_test = x_pca_test4\n",
    "X_train = x_pca4\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test4 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[135   3]\n",
      " [ 46   0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85       138\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.73       184\n",
      "   macro avg       0.37      0.49      0.42       184\n",
      "weighted avg       0.56      0.73      0.63       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = generate_auth_dataset(df,5, ratio=3)\n",
    "df5_test = generate_auth_dataset(df_test,5, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df5.iloc[:, :-1].values, df5.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data5 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df5_test.iloc[:, :-1].values, df5_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test5 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data)\n",
    "x_pca5 = pca.transform(scaled_data5)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test5)\n",
    "x_pca_test5 = pca.transform(scaled_data_test5)\n",
    "\n",
    "X_test = x_pca_test5\n",
    "X_train = x_pca5\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test5 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[137   1]\n",
      " [ 39   7]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87       138\n",
      "           1       0.88      0.15      0.26        46\n",
      "\n",
      "    accuracy                           0.78       184\n",
      "   macro avg       0.83      0.57      0.57       184\n",
      "weighted avg       0.80      0.78      0.72       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6 = generate_auth_dataset(df,6, ratio=3)\n",
    "df6_test = generate_auth_dataset(df_test,6, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df6.iloc[:, :-1].values, df6.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data6 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df6_test.iloc[:, :-1].values, df6_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test6 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data6)\n",
    "x_pca6 = pca.transform(scaled_data6)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test6)\n",
    "x_pca_test6 = pca.transform(scaled_data_test6)\n",
    "\n",
    "X_test = x_pca_test6\n",
    "X_train = x_pca6\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test6 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[137   1]\n",
      " [ 19  27]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       138\n",
      "           1       0.96      0.59      0.73        46\n",
      "\n",
      "    accuracy                           0.89       184\n",
      "   macro avg       0.92      0.79      0.83       184\n",
      "weighted avg       0.90      0.89      0.88       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7 = generate_auth_dataset(df,7, ratio=3)\n",
    "df7_test = generate_auth_dataset(df_test,7, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df7.iloc[:, :-1].values, df7.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data7 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df7_test.iloc[:, :-1].values, df7_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test7 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data7)\n",
    "x_pca7 = pca.transform(scaled_data7)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test7)\n",
    "x_pca_test7 = pca.transform(scaled_data_test7)\n",
    "\n",
    "X_test = x_pca_test7\n",
    "X_train = x_pca7\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test7 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130   8]\n",
      " [ 44   2]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83       138\n",
      "           1       0.20      0.04      0.07        46\n",
      "\n",
      "    accuracy                           0.72       184\n",
      "   macro avg       0.47      0.49      0.45       184\n",
      "weighted avg       0.61      0.72      0.64       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df8 = generate_auth_dataset(df,8, ratio=3)\n",
    "df8_test = generate_auth_dataset(df_test,8, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df8.iloc[:, :-1].values, df8.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data8 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df8_test.iloc[:, :-1].values, df8_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test8 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data8)\n",
    "x_pca8 = pca.transform(scaled_data8)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test8)\n",
    "x_pca_test8 = pca.transform(scaled_data_test6)\n",
    "\n",
    "X_test = x_pca_test8\n",
    "X_train = x_pca8\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test8 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[133   5]\n",
      " [ 39   7]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86       138\n",
      "           1       0.58      0.15      0.24        46\n",
      "\n",
      "    accuracy                           0.76       184\n",
      "   macro avg       0.68      0.56      0.55       184\n",
      "weighted avg       0.73      0.76      0.70       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df9 = generate_auth_dataset(df,9, ratio=3)\n",
    "df9_test = generate_auth_dataset(df_test,9, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df9.iloc[:, :-1].values, df9.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data9 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df9_test.iloc[:, :-1].values, df9_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test9 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data9)\n",
    "x_pca9 = pca.transform(scaled_data9)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data_test9)\n",
    "x_pca_test9 = pca.transform(scaled_data_test9)\n",
    "\n",
    "X_test = x_pca_test9\n",
    "X_train = x_pca9\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test9 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  20]\n",
      " [ 34  12]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.81       138\n",
      "           1       0.38      0.26      0.31        46\n",
      "\n",
      "    accuracy                           0.71       184\n",
      "   macro avg       0.58      0.56      0.56       184\n",
      "weighted avg       0.68      0.71      0.69       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df10 = generate_auth_dataset(df,10, ratio=3)\n",
    "df10_test = generate_auth_dataset(df_test,10, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df10.iloc[:, :-1].values, df10.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data10 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df10_test.iloc[:, :-1].values, df10_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test10 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data10)\n",
    "x_pca10 = pca.transform(scaled_data10)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test10)\n",
    "x_pca_test10 = pca.transform(scaled_data_test10)\n",
    "\n",
    "X_test = x_pca_test10\n",
    "X_train = x_pca10\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test10 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[124  14]\n",
      " [ 45   1]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81       138\n",
      "           1       0.07      0.02      0.03        46\n",
      "\n",
      "    accuracy                           0.68       184\n",
      "   macro avg       0.40      0.46      0.42       184\n",
      "weighted avg       0.57      0.68      0.61       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df11 = generate_auth_dataset(df,11, ratio=3)\n",
    "df11_test = generate_auth_dataset(df_test,11, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df11.iloc[:, :-1].values, df11.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data11 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df11_test.iloc[:, :-1].values, df11_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test11 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data11)\n",
    "x_pca11 = pca.transform(scaled_data11)\n",
    "\n",
    "pca = PCA(n_components=65\n",
    ")\n",
    "pca.fit(scaled_data_test11)\n",
    "x_pca_test11 = pca.transform(scaled_data_test11)\n",
    "\n",
    "X_test = x_pca_test11\n",
    "X_train = x_pca11\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test11 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[137   1]\n",
      " [ 16  30]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94       138\n",
      "           1       0.97      0.65      0.78        46\n",
      "\n",
      "    accuracy                           0.91       184\n",
      "   macro avg       0.93      0.82      0.86       184\n",
      "weighted avg       0.91      0.91      0.90       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df12 = generate_auth_dataset(df,12, ratio=3)\n",
    "df12_test = generate_auth_dataset(df_test,12, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df12.iloc[:, :-1].values, df12.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data12 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df12_test.iloc[:, :-1].values, df12_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test12 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data12)\n",
    "x_pca12 = pca.transform(scaled_data12)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data_test12)\n",
    "x_pca_test12 = pca.transform(scaled_data_test12)\n",
    "\n",
    "X_test = x_pca_test12\n",
    "X_train = x_pca12\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test12 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[137   1]\n",
      " [ 43   3]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86       138\n",
      "           1       0.75      0.07      0.12        46\n",
      "\n",
      "    accuracy                           0.76       184\n",
      "   macro avg       0.76      0.53      0.49       184\n",
      "weighted avg       0.76      0.76      0.68       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df13 = generate_auth_dataset(df,13, ratio=3)\n",
    "df13_test = generate_auth_dataset(df_test,13, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df13.iloc[:, :-1].values, df13.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data13 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df13_test.iloc[:, :-1].values, df13_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test13 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data13)\n",
    "x_pca13 = pca.transform(scaled_data13)\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(scaled_data_test13)\n",
    "x_pca_test13 = pca.transform(scaled_data_test13)\n",
    "\n",
    "X_test = x_pca_test13\n",
    "X_train = x_pca13\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test13 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[138   0]\n",
      " [ 21  25]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       138\n",
      "           1       1.00      0.54      0.70        46\n",
      "\n",
      "    accuracy                           0.89       184\n",
      "   macro avg       0.93      0.77      0.82       184\n",
      "weighted avg       0.90      0.89      0.87       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df14 = generate_auth_dataset(df,14, ratio=3)\n",
    "df14_test = generate_auth_dataset(df_test,14, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df14.iloc[:, :-1].values, df14.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data14 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df14_test.iloc[:, :-1].values, df14_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test14 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data14)\n",
    "x_pca14 = pca.transform(scaled_data14)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test14)\n",
    "x_pca_test14 = pca.transform(scaled_data_test14)\n",
    "\n",
    "X_test = x_pca_test14\n",
    "X_train = x_pca14\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test14 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[137   1]\n",
      " [ 46   0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.85       138\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.74       184\n",
      "   macro avg       0.37      0.50      0.43       184\n",
      "weighted avg       0.56      0.74      0.64       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df15 = generate_auth_dataset(df,15, ratio=3)\n",
    "df15_test = generate_auth_dataset(df_test,15, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df15.iloc[:, :-1].values, df15.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data15 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df15_test.iloc[:, :-1].values, df15_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test15 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data15)\n",
    "x_pca15 = pca.transform(scaled_data15)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test15)\n",
    "x_pca_test15 = pca.transform(scaled_data_test15)\n",
    "\n",
    "X_test = x_pca_test15\n",
    "X_train = x_pca15\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test15 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128  10]\n",
      " [ 12  34]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       138\n",
      "           1       0.77      0.74      0.76        46\n",
      "\n",
      "    accuracy                           0.88       184\n",
      "   macro avg       0.84      0.83      0.84       184\n",
      "weighted avg       0.88      0.88      0.88       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df16 = generate_auth_dataset(df,16, ratio=3)\n",
    "df16_test = generate_auth_dataset(df_test,16, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df16.iloc[:, :-1].values, df16.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data16 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df16_test.iloc[:, :-1].values, df16_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test16 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data16)\n",
    "x_pca16 = pca.transform(scaled_data16)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test16)\n",
    "x_pca_test16 = pca.transform(scaled_data_test16)\n",
    "\n",
    "X_test = x_pca_test16\n",
    "X_train = x_pca16\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test16 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[138   0]\n",
      " [ 46   0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       138\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.75       184\n",
      "   macro avg       0.38      0.50      0.43       184\n",
      "weighted avg       0.56      0.75      0.64       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df17 = generate_auth_dataset(df,17, ratio=3)\n",
    "df17_test = generate_auth_dataset(df_test,17, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df15.iloc[:, :-1].values, df17.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data17 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df17_test.iloc[:, :-1].values, df17_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test17 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data17)\n",
    "x_pca17 = pca.transform(scaled_data17)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test17)\n",
    "x_pca_test17 = pca.transform(scaled_data_test17)\n",
    "\n",
    "X_test = x_pca_test17\n",
    "X_train = x_pca17\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test17 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111  27]\n",
      " [ 46   0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75       138\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.60       184\n",
      "   macro avg       0.35      0.40      0.38       184\n",
      "weighted avg       0.53      0.60      0.56       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df18 = generate_auth_dataset(df,18, ratio=3)\n",
    "df18_test = generate_auth_dataset(df_test,18, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df18.iloc[:, :-1].values, df18.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data18 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df18_test.iloc[:, :-1].values, df18_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test18 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data18)\n",
    "x_pca18 = pca.transform(scaled_data18)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test18)\n",
    "x_pca_test18 = pca.transform(scaled_data_test18)\n",
    "\n",
    "X_test = x_pca_test18\n",
    "X_train = x_pca18\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test18 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127   2]\n",
      " [ 28  15]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89       129\n",
      "           1       0.88      0.35      0.50        43\n",
      "\n",
      "    accuracy                           0.83       172\n",
      "   macro avg       0.85      0.67      0.70       172\n",
      "weighted avg       0.84      0.83      0.80       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df19 = generate_auth_dataset(df,19, ratio=3)\n",
    "df19_test = generate_auth_dataset(df_test,19, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df19.iloc[:, :-1].values, df19.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data19 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df19_test.iloc[:, :-1].values, df19_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test19 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data19)\n",
    "x_pca19 = pca.transform(scaled_data19)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test19)\n",
    "x_pca_test19 = pca.transform(scaled_data_test19)\n",
    "\n",
    "X_test = x_pca_test19\n",
    "X_train = x_pca19\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test19 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[131   1]\n",
      " [ 28  16]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90       132\n",
      "           1       0.94      0.36      0.52        44\n",
      "\n",
      "    accuracy                           0.84       176\n",
      "   macro avg       0.88      0.68      0.71       176\n",
      "weighted avg       0.85      0.84      0.81       176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df20 = generate_auth_dataset(df,20, ratio=3)\n",
    "df20_test = generate_auth_dataset(df_test,20, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df20.iloc[:, :-1].values, df20.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data20 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df20_test.iloc[:, :-1].values, df20_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test20 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data20)\n",
    "x_pca20 = pca.transform(scaled_data20)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test20)\n",
    "x_pca_test20 = pca.transform(scaled_data_test20)\n",
    "\n",
    "X_test = x_pca_test20\n",
    "X_train = x_pca20\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test20 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136   2]\n",
      " [ 26  20]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       138\n",
      "           1       0.91      0.43      0.59        46\n",
      "\n",
      "    accuracy                           0.85       184\n",
      "   macro avg       0.87      0.71      0.75       184\n",
      "weighted avg       0.86      0.85      0.83       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df21 = generate_auth_dataset(df,21, ratio=3)\n",
    "df21_test = generate_auth_dataset(df_test,21, ratio=3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat, y_train = df21.iloc[:, :-1].values, df21.iloc[:, -1].values\n",
    "scaler.fit(X_Feat)\n",
    "scaled_data21 = scaler.transform(X_Feat)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Feat_test, y_test = df21_test.iloc[:, :-1].values, df21_test.iloc[:, -1].values\n",
    "scaler.fit(X_Feat_test)\n",
    "scaled_data_test21 = scaler.transform(X_Feat_test)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data21)\n",
    "x_pca21 = pca.transform(scaled_data21)\n",
    "\n",
    "pca = PCA(n_components=65)\n",
    "pca.fit(scaled_data_test21)\n",
    "x_pca_test21 = pca.transform(scaled_data_test21)\n",
    "\n",
    "X_test = x_pca_test21\n",
    "X_train = x_pca21\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "score_test21 = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score Name</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject 1</td>\n",
       "      <td>70.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject 2</td>\n",
       "      <td>92.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject 3</td>\n",
       "      <td>72.560976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject 4</td>\n",
       "      <td>76.630435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject 5</td>\n",
       "      <td>73.369565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subject 6</td>\n",
       "      <td>78.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Subject 7</td>\n",
       "      <td>89.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Subject 8</td>\n",
       "      <td>71.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Subject 9</td>\n",
       "      <td>76.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Subject 10</td>\n",
       "      <td>70.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Subject 11</td>\n",
       "      <td>67.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Subject 12</td>\n",
       "      <td>90.760870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Subject 13</td>\n",
       "      <td>76.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Subject 14</td>\n",
       "      <td>88.586957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Subject 15</td>\n",
       "      <td>74.456522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Subject 16</td>\n",
       "      <td>88.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Subject 17</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Subject 18</td>\n",
       "      <td>60.326087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Subject 19</td>\n",
       "      <td>82.558140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Subject 20</td>\n",
       "      <td>83.522727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Subject 21</td>\n",
       "      <td>84.782609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Score Name     Scores\n",
       "0    Subject 1  70.108696\n",
       "1    Subject 2  92.073171\n",
       "2    Subject 3  72.560976\n",
       "3    Subject 4  76.630435\n",
       "4    Subject 5  73.369565\n",
       "5    Subject 6  78.260870\n",
       "6    Subject 7  89.130435\n",
       "7    Subject 8  71.739130\n",
       "8    Subject 9  76.086957\n",
       "9   Subject 10  70.652174\n",
       "10  Subject 11  67.934783\n",
       "11  Subject 12  90.760870\n",
       "12  Subject 13  76.086957\n",
       "13  Subject 14  88.586957\n",
       "14  Subject 15  74.456522\n",
       "15  Subject 16  88.043478\n",
       "16  Subject 17  75.000000\n",
       "17  Subject 18  60.326087\n",
       "18  Subject 19  82.558140\n",
       "19  Subject 20  83.522727\n",
       "20  Subject 21  84.782609"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Score Name':['Subject 1', 'Subject 2', 'Subject 3', 'Subject 4', 'Subject 5', 'Subject 6','Subject 7', 'Subject 8', 'Subject 9', 'Subject 10', 'Subject 11', 'Subject 12', 'Subject 13', 'Subject 14', 'Subject 15', 'Subject 16', 'Subject 17', 'Subject 18', 'Subject 19', 'Subject 20', 'Subject 21'],\n",
    "        'Scores':[score_test1*100, score_test2*100, score_test3*100, score_test4*100, score_test5*100, score_test6*100, score_test7*100, score_test8*100, score_test9*100, score_test10*100, score_test11*100, score_test12*100, score_test13*100, score_test14*100, score_test15*100, score_test16*100, score_test17*100, score_test18*100, score_test19*100, score_test20*100, score_test21*100]}\n",
    "\n",
    "df_score = pd.DataFrame(data)\n",
    "df_score        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.22245404229548"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score['Scores'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_score_generator():\n",
    "    for i in range(21):\n",
    "        df[i] = generate_auth_dataset(df,[i], ratio=3)\n",
    "        df_test[i] = generate_auth_dataset(df_test,[i], ratio=3)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_Feat, y_train = df[i].iloc[:, :-1].values, df[i].iloc[:, -1].values\n",
    "        scaler.fit(X_Feat)\n",
    "        scaled_data[i] = scaler.transform(X_Feat)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_Feat_test, y_test = df_test[i].iloc[:, :-1].values, df_test[i].iloc[:, -1].values\n",
    "        scaler.fit(X_Feat_test)\n",
    "        scaled_data_test[i] = scaler.transform(X_Feat_test)\n",
    "\n",
    "        pca = PCA(n_components=65)\n",
    "        pca.fit(scaled_data[i])\n",
    "        x_pca[i] = pca.transform(scaled_data[i])\n",
    "\n",
    "        pca = PCA(n_components=65)\n",
    "        pca.fit(scaled_data_test[i])\n",
    "        x_pca_test[i] = pca.transform(scaled_data_test[i])\n",
    "\n",
    "        X_test = x_pca_test[i]\n",
    "        X_train = x_pca[i]\n",
    "\n",
    "        model = SVC()\n",
    "        model.fit(X_train,y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        from sklearn.metrics import classification_report,confusion_matrix\n",
    "        from sklearn.metrics import accuracy_score\n",
    "\n",
    "        print(confusion_matrix(y_test,predictions))\n",
    "        print('\\n')\n",
    "        print(classification_report(y_test,predictions))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (1962,), (1,))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-319-c0c610cd4a2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mRandom_score_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-318-91e0be4c2ed3>\u001b[0m in \u001b[0;36mRandom_score_generator\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mRandom_score_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_auth_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_auth_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-126-307465720e63>\u001b[0m in \u001b[0;36mgenerate_auth_dataset\u001b[1;34m(df, subj, ratio)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_auth_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[0msubj_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0msubj_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubj_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0msubj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0msubj_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubj_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msubj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mgen_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubj_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubj_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;31m#  The ambiguous case is object-dtype.  See GH#27803\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    225\u001b[0m                 \u001b[1;34m\"Lengths must match to compare\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: ('Lengths must match to compare', (1962,), (1,))"
     ]
    }
   ],
   "source": [
    "Random_score_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c9b013fbfbd10b794326d2c19d5edd189c06c7c43d5cdd5adc5265cd405c3ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
